{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KinMS galaxy fitting tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial aims at getting you up and running with galaxy kinematic modelling using _KinMS_! To start you will need to download the KinMSpy code and have it in your python path (_todo: make pip installable_).\n",
    "\n",
    "To do this we will complete the following steps:\n",
    "1. Generate a model to fit (can be skipped if you have your own observed data cube)\n",
    "2. Read in that cube, and extract the important information from the header\n",
    "3. Fit the data using an MCMC code\n",
    "\n",
    "We will start by importing a variety of modules we will need to work with KinMS, and plot its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KinMS import *\n",
    "import numpy as np\n",
    "from astropy.io import fits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will generate a simple galaxy model using KinMS itself, that we can attempt to determine the parameters of later. If you have your own observed galaxy to fit then of course this step can be skipped!\n",
    "\n",
    "The `make_model` function below creates a simple exponential disc:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\large \\Sigma_{H2}(r) \\propto e^{\\frac{-r}{d_{scale}}}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "with a circular velocity profile which is parameterized using an arctan function:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "\\large V(r) = \\frac{2V_{flat}}{\\pi} \\arctan\\left(\\frac{r}{r_{turn}}\\right)\n",
    "\\end{align}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(param,obspars,rad,filename=None):\n",
    "    '''\n",
    "    This function takes in the `param` array (along with obspars; the observational setup,\n",
    "    and a radius vector `rad`) and uses it to create a KinMS model.\n",
    "    '''\n",
    "    \n",
    "    total_flux=param[0]\n",
    "    posAng=param[1]\n",
    "    inc=param[2]\n",
    "    v_flat=param[3]\n",
    "    r_turn=param[4]\n",
    "    scalerad=param[5]\n",
    "    \n",
    "    ### Here we use an exponential disk model for the surface brightness of the gas ###\n",
    "    sbprof = np.exp((-1)*rad/scalerad)\n",
    "\n",
    "    ### We use a very simple arctan rotation curve model with two free parameters. ###\n",
    "    vel=(v_flat*2/np.pi)*np.arctan(rad/r_turn)\n",
    "\n",
    "    ### This returns the model\n",
    "    return KinMS(obspars['xsize'],obspars['ysize'],obspars['vsize'],obspars['cellsize'],obspars['dv'],\\\n",
    "                 obspars['beamsize'],inc,sbProf=sbprof,sbRad=rad,velRad=rad,velProf=vel,\\\n",
    "                 intFlux=total_flux,posAng=posAng,fixSeed=True,fileName=filename)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have set `fixSeed=True` in the KinMS call - this is crucial if you are fitting with KinMS. It ensures if you generate two models with the same input parameters you will get an identical output model! \n",
    "\n",
    "Now we have our model function, lets use it to generate a model which we will later fit. The first thing we need is to define the setup of our desired datacube (typically if you are fitting real data this will all be determined from the header keywords- see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup cube parameters ###\n",
    "obspars={}\n",
    "obspars['xsize']=64.0 # arcseconds\n",
    "obspars['ysize']=64.0 # arcseconds\n",
    "obspars['vsize']=500.0 # km/s\n",
    "obspars['cellsize']=1.0 # arcseconds/pixel\n",
    "obspars['dv']=20.0 # km/s/channel\n",
    "obspars['beamsize']=np.array([4.0,4.0,0]) # [bmaj,bmin,bpa] in (arcsec, arcsec, degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create a radius vector- you ideally want this to oversample your pixel grid somewhat to avoid interpolation errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad=np.arange(0,100,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the ingredients we can create our data to fit. Here we will also output the model to disc, so we can demonstrate how to read in the header keywords from real ALMA/VLA etc data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "True values for the flux, posang, inc etc, as defined in the model function\n",
    "'''\n",
    "\n",
    "guesses=np.array([30.,270.,45.,200.,2.,5.]) \n",
    "\n",
    "'''\n",
    "RMS of data. Here we are making our own model so this is arbitary. \n",
    "When fitting real data this should be the observational RMS\n",
    "'''\n",
    "error=np.array(1e-3)\n",
    "\n",
    "\n",
    "fdata=make_model(guesses,obspars,rad, filename=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we already have our data in memory. But if you are fitting a real datacube this wont be the case!  Here we read in the model we just created from a FITS file to make it clear how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in your observational data ###\n",
    "hdulist = fits.open('Test_simcube.fits',ignore_blank=True)\n",
    "fdata = hdulist[0].data.T \n",
    "\n",
    "\n",
    "### Setup cube parameters ###\n",
    "obspars={}\n",
    "obspars['cellsize']=np.abs(hdulist[0].header['cdelt1']*3600.) # arcseconds/pixel\n",
    "obspars['dv']=np.abs(hdulist[0].header['cdelt3']/1e3) # km/s/channel\n",
    "obspars['xsize']=hdulist[0].header['naxis1']*obspars['cellsize'] # arcseconds\n",
    "obspars['ysize']=hdulist[0].header['naxis2']*obspars['cellsize'] # arcseconds\n",
    "obspars['vsize']=hdulist[0].header['naxis3']*obspars['dv'] # km/s\n",
    "obspars['beamsize']=np.array([hdulist[0].header['bmaj']*3600.,hdulist[0].header['bmin']*3600.,hdulist[0].header['bpa']])# [bmaj,bmin,bpa] in (arcsec, arcsec, degrees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now we have our 'observational' data read into memory, and a model function defined, we can fit one to the other! As our fake model is currently noiseless, lets add some gaussian noise (obviously dont do this if your data is from a real telecope!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata+=(np.random.normal(size=fdata.shape)*error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit this noisy data. Below we will proceed using the MCMC code GAStimator which was specifically designed to work with KinMS, however any minimiser should work in principle. For full details of how this code works, and a tutorial, see https://github.com/TimothyADavis/GAStimator ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gastimator import gastimator,corner_plot\n",
    "\n",
    "mcmc = gastimator(make_model,obspars,rad)\n",
    "\n",
    "mcmc.labels=np.array(['Flux','posAng',\"Inc\",\"VFlat\",\"R_turn\",\"scalerad\"])\n",
    "mcmc.min=np.array([30.,1.,10,50,0.1,0.1])\n",
    "mcmc.max=np.array([30.,360.,80,400,20,10])\n",
    "mcmc.fixed=np.array([True,False,False,False,False,False])\n",
    "mcmc.precision=np.array([1.,1.,1.,10,0.1,0.1])\n",
    "mcmc.guesses=guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting good priors on the flux of your source is crucial to ensure the model outputs are physical. Luckily the integrated flux of your source should be easy to measure from your datacube! If you have a good measurement of this, then I would recommend forcing the total flux to that value by fixing it in the model (set `mcmc.fixed=True` for that parameter). If you can only get a guess then set as tight a prior as you can. This stops the model hiding bad fitting components below the noise level. \n",
    "\n",
    "Once you have set up your parameters, you can run the fit! If you are experimenting then running until convergence should be good enough to get an idea if the model is physical (setting a low number of iterations, ~3000 works for me)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing chain 1\n",
      "     Chain has not converged - Accept rate: 0.013333333333333334\n",
      "     Chain has not converged - Accept rate: 0.056666666666666664\n",
      "Target rate not reached\n",
      "Chain converged: LL: -50915.04006517966 - Accept rate:0.2833333333333333\n",
      "Best chain so far!\n",
      "verybestparam [ 30.         269.98917462  44.98136747 200.11493151   2.00031424\n",
      "   5.00821359]\n",
      "Starting final chain\n",
      "verybestparam final [ 30.         269.96631945  44.92033052 200.34153913   2.00260773\n",
      "   5.00063427]\n",
      "[0.         0.03109563 0.07995005 0.23920072 0.00811045 0.00701432]\n"
     ]
    }
   ],
   "source": [
    "outputvalue, outputll= mcmc.run(fdata,error,3000,numatonce=300,plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the final parameters (listed in the output as `verybestparam final`) are pretty close to those we input! One could use the cornor_plot routine shipped with GAStimator to visualize our results, but with only 3000 steps (and at 30% acceptance rate) these wont be very pretty. If you need good error estimates/nice looking cornor plots for publication then I recommend at least 30,000+ iterations, which may take several hours/days depending on your system/model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed tips\n",
    "\n",
    "There are some common ways to make sure you don't spend a lot of time MCMCing rather than doing science. \n",
    "\n",
    "- Cut down your observed data to only include spaxels and frequency channels near signal. Ideally you want some padding around your observed signal so the model knows it must not include flux in those positions, but not so much as to drastically increase runtime! On a similar note...<p>\n",
    "\n",
    "- Make sure your observed data (and thus models) have spatial dimensions that are $2^n$. If this is impossible then $3^n$ and $6^n$ are pretty good too. This is because convolving the KinMS model with the beam takes the majority of the computation time, and FFTs are faster when working with such dimensions.<p>\n",
    "\n",
    "- Don't provide a radius vector that is very oversampled/overlong well beyond the projected dimensions of the cube. This can slow down internal interpolation routines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
